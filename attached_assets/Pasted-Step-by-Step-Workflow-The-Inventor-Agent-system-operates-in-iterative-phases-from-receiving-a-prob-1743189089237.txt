Step-by-Step Workflow

The Inventor Agent system operates in iterative phases, from receiving a problem statement to producing a finalized invention. Below is the structured workflow, with each step indicating which agent(s) are active and how information flows between them:

    Problem Definition & Initialization: The process begins when a general problem statement or hypothesis is provided (for example, “Design a more efficient sorting algorithm” or “Propose a molecule that could treat Alzheimer’s disease by targeting protein X”). The Orchestrator/Manager agent (or CrewAI’s controller) interprets this input and sets the overall goal. It may decompose the problem if needed or clarify objectives. The problem is then broadcast to the relevant agents, especially the Inventor Agent as the starting point. All agents may load initial context or constraints from the problem description.

    Ideation by Inventor Agent: Using the problem as a prompt, the Inventor Agent generates one or several candidate ideas. This could be a high-level concept for an algorithm (e.g., a new sorting technique using a hybrid of quicksort and DP, described in pseudocode form) or a proposed chemical structure with certain functional groups. The generation might involve creative strategies like analogy (relating to known ideas in the vector knowledge base), combination (merging features of multiple known solutions), or purely heuristic innovation. The Inventor may produce multiple distinct concepts in this step to explore the solution space. Each concept is output as a clear description (and perhaps initial pseudocode or a molecular sketch) to the shared workspace. If multiple ideas are generated, the Orchestrator can either carry them all forward for evaluation or prune some based on obvious viability checks. At this stage, the ideas are raw and unvalidated.

    Contextual Research (Researcher Agent): As soon as an idea is proposed, the Researcher Agent kicks in to gather context and background. For each concept (or the general problem if more appropriate), the Researcher performs focused queries:

        It searches academic papers, patents, and web sources for similar concepts. The goal is to find whether the idea (or parts of it) has precedent and what existing solutions exist. For instance, if the Inventor came up with a “dynamic programming sort algorithm,” the Researcher might discover prior work on hybrid sorting algorithms or any known optimal sorting methods.

        It pulls relevant data: definitions, equations, prior results, experimental data, etc. If the invention is a molecule, the Researcher might retrieve known data about that class of compounds or the disease target.

        The Researcher then compiles a concise summary of findings. This could include excerpts from sources or a list of similar approaches found. It will highlight anything that looks like the Inventor’s idea (which is critical for the Evaluator’s novelty check) and any known issues or principles (critical for feasibility check). The information is shared with the Evaluator and Refiner agents (via common memory or direct message).

    Feasibility & Novelty Evaluation (Evaluator Agent): With the Inventor’s idea and the Researcher’s context in hand, the Evaluator Agent critically assesses the proposal:

        Novelty Analysis: The Evaluator compares the idea against known solutions. It utilizes the Researcher’s findings (e.g., if the Researcher found a paper with a similar algorithm, the Evaluator notes the overlap) and may also query the vector knowledge base for semantic similarity. If the idea is an algorithm, the Evaluator checks if its approach or complexity is unique relative to known algorithms. If it’s a molecule, the Evaluator might check if that exact structure or very close analogs exist in patent or chemical databases. A score or flag is assigned for novelty (e.g., high novelty if nothing similar was found, or low novelty if it appears to replicate known ideas). This process ensures the system strives for original inventions​
        file-yk37sywukcz9lgemipzwzj
        .

        Feasibility Analysis: The Evaluator examines whether the idea is practical and sound. For an algorithm, it would verify logical correctness (does the method make sense?), estimate time/space complexity, and consider implementation constraints. It might run a simplified version of the algorithm on test data to ensure it produces correct results. For a molecular invention, feasibility involves checking synthetic accessibility (can chemists likely synthesize this molecule?), stability, and compliance with known rules (e.g., drug-likeness filters if it’s a drug candidate). The Evaluator might use any domain simulators here, such as executing pseudocode or calling a chemistry property prediction API. Any red flags (e.g., “the algorithm would be O(n^3) which is too slow” or “the molecule is probably toxic due to a functional group”) are noted.

        Scoring & Feedback: The Evaluator then consolidates its findings into feedback. It might provide scores (e.g., Novelty = 8/10, Feasibility = 5/10) and a written critique. The critique will list strengths (what the idea does well or novel aspects) and weaknesses (overlaps with prior art, logical issues, inefficiencies, etc.), as well as suggestions on how to improve. If multiple ideas were being evaluated in parallel, the Evaluator ranks them from most promising to least​
        file-yk37sywukcz9lgemipzwzj
        , possibly dropping any that clearly won’t work or are not novel. The top candidate(s) move to the next step.

    Feedback Loop Decision (Orchestrator/Team): The system now decides whether the invention is ready or needs iteration. The Orchestrator (or a decision logic) looks at the Evaluator’s feedback:

        If the idea already meets a high novelty and feasibility threshold (e.g., the Evaluator is very positive, and little improvement is needed), the process can move directly to final documentation. This might happen if the Inventor’s first attempt was very successful or if time is limited.

        More commonly, the idea will need refinement. In that case, the feedback and research findings are fed into the next phase. The Orchestrator might specifically highlight the biggest issues to tackle first (for example, “Idea is promising but too similar to X, needs a more novel twist” or “Feasibility is low due to Y, fix that aspect”). This sets the agenda for the Refiner Agent. The state (current concept and all critique) remains in a shared memory or is passed explicitly to the Refiner.

    Refinement (Refiner Agent): Based on the feedback, the Refiner Agent works on improving the invention concept. This is an iterative design step aimed at addressing weaknesses or incorporating suggestions:

        The Refiner might adjust parameters or components of the idea. For algorithms, this could mean altering steps, using a different data structure, or combining the approach with another algorithm to handle edge cases or reduce complexity. For molecules, it could involve modifying a substructure (e.g., replacing a potentially toxic moiety, or adding a functional group known to increase potency).

        The Refiner uses information from the Evaluator and Researcher to guide changes. For example, if the Evaluator pointed out that “Method is too similar to Algorithm A from 2020”, the Refiner will consciously introduce a differentiating element. Or if “the molecule likely won’t cross the blood-brain barrier”, the Refiner might add a polar group to improve its profile.

        Sometimes the Refiner may consult the Inventor Agent for creative ways to implement the requested changes (this could be seen as the Inventor agent being invoked again with more specific instructions). In effect, the line between Inventor and Refiner can blur during iterative development – the key distinction is that the Refiner’s actions are driven by specific feedback rather than a blank-slate creation.

        The output of the Refiner is a revised invention concept. It will be put back into the shared workspace, typically annotated as “Version 2” of the idea.

    Iterative Loop (Ideate–Evaluate–Refine): The newly refined concept is fed back to the Researcher and Evaluator for another round. The workflow returns to step 3 (Researcher updates any new context if needed – e.g., check if the revised idea now overlaps with something else or if new data is needed) and then step 4 (Evaluator re-evaluates the updated concept). The agents collaboratively loop through generation and critique cycles until a satisfying result emerges. This closed-loop approach, where each iteration improves upon the last, continues until one of the following conditions is met:

        Success Criterion Achieved: The invention idea is judged novel and feasible enough. For instance, after a few iterations, the Evaluator might report “All major issues resolved – the algorithm is unlike known ones and seems efficient” or “The molecule is novel and predicted safe; no further critiques”. At this point, the Evaluator/Orchestrator sets a flag that the solution is ready.

        Iteration Limit: A predefined maximum number of iterations or time budget is reached. If the system hasn’t converged on an acceptable idea by then, it may take the best attempt so far to finalize (or, if instructed, report failure). This prevents infinite loops on intractable problems. In practice, many inventive processes might converge after a handful of cycles, given targeted feedback.

        Dead-end or Re-specification: If during evaluation it becomes clear the current approach will not yield a viable invention (e.g., every variant the Refiner tries still clashes with existing prior art or fundamental limitations), the system might decide to go back to the drawing board. The Orchestrator could either prompt the Inventor agent to generate a completely new idea (starting a fresh loop with a different approach), or if allowed, adjust the original problem statement/hypothesis. This is a higher-level feedback where the system essentially says “We need a different strategy to solve this problem.” When this happens, a new cycle begins with step 2 but informed by what was learned (the previous attempts can be logged so the Inventor doesn’t repeat those paths).

        Throughout the loop, the system may employ a Proximity/Diversity check to avoid redundant cycles. A Proximity Agent (if included) can ensure that each new idea or iteration is meaningfully different from previous ones​
        file-yk37sywukcz9lgemipzwzj
        . This prevents oscillating between similar variants or revisiting concepts that were already deemed unsuitable, thereby streamlining the search in the design space.

    Final Validation: Once a candidate invention passes the evaluation criteria (or the loop ends with a best-effort solution), the Evaluator does a last check. Any final minor issues are noted for documentation (if they exist), and the solution is flagged as the outcome. At this stage, the team has essentially “approved” the invention as novel and feasible to the best of their knowledge. The Orchestrator then proceeds to the output stage.

    Documentation and Output (Documenter Agent): The Documenter Agent now takes the baton to produce the outputs of the system. This involves assembling all the relevant information about the new invention into a coherent format for end users (researchers, engineers, etc.):

        It writes a conceptual design report describing the invention in detail. For an algorithm, this would include the problem context, the principles of the new algorithm, how it differs from existing ones, and pseudocode or flowcharts for implementation. It might also include complexity analysis and any test results obtained during evaluation. For a molecular invention, the report would describe the rationale for the molecule, its structure (maybe with an image of the chemical structure), predicted properties (from the Evaluator’s analysis), and suggestions for laboratory synthesis and testing protocols (this serves as “research replication instructions” for chemists to actually create and evaluate the compound).

        The Documenter incorporates citations and references from the Researcher Agent’s findings to acknowledge prior work and situate the invention in context. For example, “Unlike the method by Smith et al. (2023)​
        deepmind.google
        , our algorithm does X” or “No compounds in the literature match this structure​
        arxiv.org
        , indicating its novelty.” This gives credibility and clarity to the output.

        It also lists any assumptions or requirements identified during the process (e.g., “This algorithm assumes a distributed memory model” or “The proposed drug is intended to bind protein X as confirmed by docking studies”).

        If the output requires multi-format deliverables, the Documenter prepares them. For instance, alongside the written report, it might output the actual pseudocode file or a JSON specifying the molecule structure.

        The final packaged result is then presented as the system’s invention deliverable. At this point, human users could review it, implement it, or test it in the real world. The Documenter’s role is to make sure the autonomous process is transparent and reproducible to humans.